{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_default_device\", jax.devices()[1])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "from tqdm.auto import tqdm\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from importlib import reload\n",
    "import KernelTools\n",
    "reload(KernelTools)\n",
    "from KernelTools import *\n",
    "from EquationModel import OperatorModel,SplitOperatorPDEModel,OperatorPDEModel\n",
    "from evaluation_metrics import compute_results    \n",
    "from data_utils import MinMaxScaler\n",
    "from evaluation_metrics import get_nrmse\n",
    "\n",
    "from Kernels import log1pexp,inv_log1pexp\n",
    "from Kernels import (\n",
    "    get_centered_scaled_poly_kernel,\n",
    "    get_anisotropic_gaussianRBF,\n",
    "    fit_kernel_params\n",
    ")\n",
    "from EquationModel import CholInducedRKHS, CholOperatorModel, OperatorPDEModel\n",
    "from functools import partial\n",
    "\n",
    "import Optimizers\n",
    "import importlib\n",
    "importlib.reload(Optimizers)\n",
    "from Optimizers import CholeskyLM,SVD_LM\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import cm\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# from pyDOE import lhs\n",
    "# #    import sobol_seq\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from lineax import CG\n",
    "import lineax\n",
    "\n",
    "x,sol = jax.scipy.sparse.linalg.cg(lambda x:jnp.linspace(1,100,10)*x,jnp.ones(10),jnp.zeros(10),maxiter = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_rand_coll(n_coll, n_obs,seed, data_for_pinn = False): \n",
    "    '''\n",
    "    n_coll (int) : Integer less than 101 x 256.\n",
    "    n_obs (int)    : Integet less than 101 x 256.\n",
    "    seed (int)     : Seed to choose data point set.\n",
    "    '''     \n",
    "    # Generate data\n",
    "    data = scipy.io.loadmat('/home/juanfelipe/Desktop/research/keql/examples/burgers/data/burgers.mat')\n",
    "    # t\n",
    "    t = jnp.real(data['t'].flatten()[:,None])\n",
    "    # # Scale t\n",
    "    # scaler_t = MinMaxScaler()\n",
    "    # t = scaler_t.fit_transform(t)\n",
    "    # x\n",
    "    x = np.real(data['x'].flatten()[:,None])\n",
    "    # # Scale x\n",
    "    # scaler_x = MinMaxScaler()\n",
    "    # x = scaler_x.fit_transform(x)\n",
    "    # u true values\n",
    "    Exact = np.real(data['usol'])\n",
    "\n",
    "    # Fine meshgrid\n",
    "    T, X = np.meshgrid(t,x)\n",
    "\n",
    "    # Fine pairs (t,x)\n",
    "    X_star = np.hstack((T.flatten()[:,None], X.flatten()[:,None]))\n",
    "    # Fine u values\n",
    "    u_star = Exact.flatten()[:,None]\n",
    "    \n",
    "    # Triples at collocation point set\n",
    "    N_all = n_coll\n",
    "    triplets_fine = np.hstack([X_star,u_star])\n",
    "    triplets_all = jax.random.choice(key = jax.random.PRNGKey(0), a = triplets_fine, shape = (N_all,), replace=False)\n",
    "    \n",
    "    # Collocation point set\n",
    "    tx_all = triplets_all[:,:2]\n",
    "\n",
    "\n",
    "    N_obs = n_obs\n",
    "    triplets_obs = jax.random.choice(key = jax.random.PRNGKey(seed), a = triplets_fine, shape = (N_obs,), replace=False)\n",
    "    # triplets_obs = triplets_all[idx_obs,:] # Choose data point set from full point set\n",
    "    # Data point set\n",
    "    tx_obs = triplets_obs[:,:2]\n",
    "    u_obs = triplets_obs[:,-1]\n",
    "\n",
    "    u_star = triplets_fine[:,-1]\n",
    "\n",
    "    # Invert them to be ready for PINNSR\n",
    "    if data_for_pinn:\n",
    "        tx_train = tx_train.at[:,[1,0]].set(tx_train[:,[0,1]])\n",
    "\n",
    "        tx_val = tx_val.at[:,[1,0]].set(tx_val[:,[0,1]])\n",
    "\n",
    "        tx_all = tx_all.at[:,[1,0]].set(tx_all[:,[0,1]])\n",
    "\n",
    "        X_star = X_star.at[:,[1,0]].set(X_star[:,[0,1]])\n",
    "\n",
    "        triplets_fine = triplets_fine.at[:,[1,0]].set(triplets_fine[:,[0,1]])\n",
    "    \n",
    "    return tx_obs, u_obs, tx_all, u_star, X_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.75730243 0.7683696 ]\n"
     ]
    }
   ],
   "source": [
    "n_coll_t = 30\n",
    "n_coll_x=30\n",
    "n_obs = 500\n",
    "run = 100\n",
    "\n",
    "tx_obs, u_obs, tx_all, u_star, X_star = (\n",
    "    get_data_rand_coll(n_coll = 1000,n_obs = n_obs,seed=run)\n",
    ")\n",
    "tx_all = jnp.vstack([tx_all,jnp.vstack([jnp.zeros(30),jnp.linspace(-8,8,30)]).T])\n",
    "\n",
    "# # if using val\n",
    "# tx_obs = jnp.vstack([tx_train,tx_val])\n",
    "# u_obs  = jnp.concatenate([u_train,u_val]).flatten()    \n",
    "\n",
    "# Run 1_5 step method\n",
    "\n",
    "u_operators = (eval_k,)\n",
    "feature_operators = (eval_k,dx_k,dxx_k)\n",
    "\n",
    "# Choose u kernel\n",
    "def param_ani_gaussian_RBF(x,y,params):\n",
    "    lengthscales = log1pexp(params)\n",
    "    return get_anisotropic_gaussianRBF(1.,jnp.diag(lengthscales))(x,y)\n",
    "\n",
    "fitted_params,ml_value = fit_kernel_params(param_ani_gaussian_RBF,tx_obs,u_obs,jnp.zeros(2))\n",
    "ML_lengthscales = log1pexp(fitted_params)\n",
    "print(1/(jnp.sqrt(ML_lengthscales)))\n",
    "k_u = get_anisotropic_gaussianRBF(1.,jnp.diag(jnp.array([1.,1.])))\n",
    "\n",
    "# RKHS class for u\n",
    "u_model = CholInducedRKHS(\n",
    "    tx_all,\n",
    "    u_operators,\n",
    "    k_u,\n",
    "    nugget_size = 1e-8\n",
    "    )\n",
    "u_params_init = u_model.get_fitted_params(tx_obs,u_obs)\n",
    "\n",
    "grid_features_init = (\n",
    "    (u_model.evaluate_operators(feature_operators,tx_all,u_params_init))\n",
    "    .reshape(\n",
    "            len(tx_all),\n",
    "            len(feature_operators),\n",
    "            order = 'F'\n",
    "        )\n",
    ")\n",
    "\n",
    "# Choose kernel for P\n",
    "k_P_u_part = get_centered_scaled_poly_kernel(2,grid_features_init,c=1.,scaling = 'diagonal')\n",
    "@vectorize_kfunc\n",
    "def k_P(x,y):\n",
    "    return k_P_u_part(x[2:],y[2:])\n",
    "P_model = OperatorModel(k_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def get_monomial_feature_list(dim,degree):\n",
    "    return sum([list(combinations_with_replacement(range(dim),r = d)) for d in range(1,degree+1)],[])\n",
    "\n",
    "def get_polynomial_feature_map(monomial_feature_list):\n",
    "    def poly_features(X):\n",
    "        return jnp.array([jnp.ones(len(X))]+[jnp.prod(X[:,inds],axis=1) for inds in monomials]).T\n",
    "    return poly_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyFeatures():\n",
    "    def __init__(\n",
    "        self,\n",
    "        degree,\n",
    "        processed_dimension,\n",
    "        preprocessor = lambda x:x,\n",
    "        data_to_scale = None,\n",
    "    ):\n",
    "        self.degree = degree\n",
    "        self.input_dimension = processed_dimension\n",
    "        self.preprocessor = preprocessor\n",
    "        self.monomials = get_monomial_feature_list(processed_dimension,degree = degree)\n",
    "        self.feature_map = get_polynomial_feature_map(self.monomials)\n",
    "        self.feature_dim = len(self.monomials)+1\n",
    "\n",
    "    def predict(self,features,params):\n",
    "        return self.feature_map(self.preprocessor(features))@params\n",
    "    \n",
    "    def rkhs_mat(self,X):\n",
    "        return jnp.identity(self.feature_dim)\n",
    "\n",
    "\n",
    "class OperatorModel():\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel,\n",
    "        nugget_size = 1e-7\n",
    "    ):\n",
    "        self.kernel_function = kernel\n",
    "        self.nugget_size = nugget_size\n",
    "\n",
    "    def predict(self,input_data,params):\n",
    "        K = self.kernel_function(input_data,input_data)\n",
    "        return K@params\n",
    "        \n",
    "    def predict_new(self,X,anchors,params):\n",
    "        return self.kernel_function(X,anchors)@params\n",
    "    \n",
    "    def fit_params(self,X,y,nugget = 1e-8):\n",
    "        K = self.kernel_function(X,X)\n",
    "        return jnp.linalg.solve(K + nugget * diagpart(K),y)\n",
    "    \n",
    "    def rkhs_mat(self,X):\n",
    "        return self.kernel_function(X,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac49bed472bc4b1ab114cc8507c34865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.002082, Jres = 0.01379, alpha = 0.08333, improvement_ratio = 0.9981\n",
      "Iteration 1, loss = 0.001558, Jres = 0.008866, alpha = 0.06944, improvement_ratio = 1.0\n",
      "Iteration 2, loss = 0.001265, Jres = 0.005981, alpha = 0.05787, improvement_ratio = 1.001\n",
      "Iteration 3, loss = 0.001095, Jres = 0.004096, alpha = 0.04823, improvement_ratio = 1.0\n",
      "Iteration 4, loss = 0.0009908, Jres = 0.002872, alpha = 0.04019, improvement_ratio = 1.0\n",
      "Iteration 5, loss = 0.0009213, Jres = 0.002075, alpha = 0.03349, improvement_ratio = 1.001\n",
      "Iteration 100, loss = 3.245e-05, Jres = 1.964e-06, alpha = 8.333e-07, improvement_ratio = 1.003\n",
      "Iteration 200, loss = 2.413e-05, Jres = 4.27e-07, alpha = 8.333e-07, improvement_ratio = 1.001\n",
      "Iteration 300, loss = 2.096e-05, Jres = 1.969e-07, alpha = 8.333e-07, improvement_ratio = 1.0\n",
      "Iteration 400, loss = 1.917e-05, Jres = 1.375e-07, alpha = 8.333e-07, improvement_ratio = 1.0\n",
      "Iteration 500, loss = 1.799e-05, Jres = 1.101e-07, alpha = 8.333e-07, improvement_ratio = 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7d05fb5fad423fbe2b6965ea6cfcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.79543293061942e-05\n",
      "Iteration 10, loss = 1.795317258556761e-05\n",
      "Iteration 20, loss = 1.791252347926775e-05\n",
      "Iteration 30, loss = 1.6750273488753976e-05\n",
      "Iteration 40, loss = 1.1170969972577893e-05\n",
      "Iteration 50, loss = 7.243154683124377e-06\n",
      "Iteration 60, loss = 5.786375468752498e-06\n",
      "Iteration 60 Step Failed\n",
      "Iteration 61 Step Failed\n",
      "Iteration 62 Step Failed\n",
      "Iteration 63 Step Failed\n",
      "Iteration 65 Step Failed\n",
      "Iteration 66 Step Failed\n",
      "Iteration 68 Step Failed\n",
      "Iteration 70, loss = 5.786352896709283e-06\n",
      "Iteration 70 Step Failed\n",
      "Iteration 71 Step Failed\n",
      "Iteration 73 Step Failed\n",
      "Iteration 74 Step Failed\n",
      "Iteration 75 Step Failed\n",
      "Iteration 76 Step Failed\n",
      "Iteration 77 Step Failed\n",
      "Iteration 78 Step Failed\n",
      "Iteration 79 Step Failed\n",
      "Iteration 80, loss = 5.786352766802076e-06\n",
      "Iteration 80 Step Failed\n",
      "Iteration 81 Step Failed\n",
      "Iteration 84 Step Failed\n",
      "Iteration 85 Step Failed\n",
      "Iteration 86 Step Failed\n",
      "Iteration 87 Step Failed\n",
      "Iteration 88 Step Failed\n",
      "Iteration 89 Step Failed\n",
      "Iteration 90, loss = 5.786351972318834e-06\n",
      "Iteration 90 Step Failed\n",
      "Iteration 91 Step Failed\n",
      "Iteration 92 Step Failed\n",
      "Iteration 93 Step Failed\n",
      "Converged by no improvement\n"
     ]
    }
   ],
   "source": [
    "PolyModel = PolyFeatures(degree = 2,processed_dimension=3,preprocessor = lambda x:x[:,2:])\n",
    "\n",
    "# Equation model that has u and P object\n",
    "EqnModel = SplitOperatorPDEModel(\n",
    "    PolyModel,\n",
    "    (u_model,),\n",
    "    (tx_obs,),\n",
    "    (u_obs,),\n",
    "    (tx_all,),\n",
    "    feature_operators,\n",
    "    rhs_operator=dt_k,\n",
    "    datafit_weight = 100,\n",
    "    num_P_operator_params=PolyModel.feature_dim\n",
    ")\n",
    "\n",
    "# Optimize - LM\n",
    "params_init = jnp.hstack([u_params_init,jnp.zeros(PolyModel.feature_dim)])\n",
    "params,convergence_data = CholeskyLM(\n",
    "    params_init.copy(),\n",
    "    EqnModel,\n",
    "    beta = 1e-11,\n",
    "    max_iter = 501,\n",
    "    init_alpha=0.1,\n",
    "    line_search_increase_ratio=1.4,\n",
    "    print_every = 100\n",
    ")\n",
    "p_adjusted,refine_convergence_data = SVD_LM(params,EqnModel,1e-3,100,print_every = 10,overall_regularization=1e-13)\n",
    "# u_params\n",
    "u_sol = p_adjusted[:u_model.num_params]\n",
    "# u_true \n",
    "u_true = u_star.flatten()\n",
    "# get error\n",
    "error_u_field = get_nrmse(u_true, u_model.point_evaluate(X_star,u_sol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016826812744712125\n"
     ]
    }
   ],
   "source": [
    "print(error_u_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,), (1,), (2,), (0, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 2)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PolyModel.monomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ut' = -0.000 + 0.032 (ux) + 0.097 (uxx) + -1.096 (u)(ux) + -0.059 (ux)(uxx) \n"
     ]
    }
   ],
   "source": [
    "P_coeffs = EqnModel.get_P_params(p_adjusted)\n",
    "\n",
    "threshold = 3e-2\n",
    "var_names = ['(u)','(ux)','(uxx)']\n",
    "eqn = f\"ut' = {P_coeffs[0]:.3f} \"\n",
    "for val,term in zip(P_coeffs[1:],PolyModel.monomials):\n",
    "    if jnp.abs(val)>=threshold:\n",
    "        equation_addition = f\"+ {val:.3f} {''.join([var_names[i] for i in term])} \"\n",
    "        eqn = eqn + equation_addition\n",
    "print(eqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysindy.optimizers.stlsq import STLSQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ut' = 0.000 + 1.068 (uxx) + -0.101 (u)(uxx) + 0.214 (ux)(uxx) + -1.011 (uxx)(uxx) \n"
     ]
    }
   ],
   "source": [
    "final_features = EqnModel.single_eqn_features(u_model,u_sol,tx_all)\n",
    "poly_final = PolyModel.feature_map(final_features)\n",
    "target_final = EqnModel.apply_rhs_op_single(u_model,u_sol,tx_all)\n",
    "\n",
    "stlsq = STLSQ(threshold = 1e-2,alpha = 0,max_iter = 100)\n",
    "stlsq.fit(poly_final,target_final)\n",
    "\n",
    "poly_coeffs = stlsq.coef_[0]\n",
    "\n",
    "\n",
    "threshold = 1e-4\n",
    "var_names = ['(u)','(ux)','(uxx)']\n",
    "eqn = f\"ut' = {poly_coeffs[0]:.3f} \"\n",
    "for val,term in zip(poly_coeffs[1:],PolyModel.monomials):\n",
    "    if jnp.abs(val)>=threshold:\n",
    "        equation_addition = f\"+ {val:.3f} {''.join([var_names[i] for i in term])} \"\n",
    "        eqn = eqn + equation_addition\n",
    "print(eqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 10), dtype=float64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stlsq.coef_[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
