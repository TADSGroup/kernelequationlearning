{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_default_device\", jax.devices()[1])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "from tqdm.auto import tqdm\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from importlib import reload\n",
    "import KernelTools\n",
    "reload(KernelTools)\n",
    "from KernelTools import *\n",
    "from EquationModel import OperatorModel,SplitOperatorPDEModel,OperatorPDEModel,InducedOperatorModel\n",
    "from evaluation_metrics import compute_results    \n",
    "from data_utils import MinMaxScaler\n",
    "from evaluation_metrics import get_nrmse\n",
    "\n",
    "from Kernels import log1pexp,inv_log1pexp\n",
    "from Kernels import (\n",
    "    get_centered_scaled_poly_kernel,\n",
    "    get_anisotropic_gaussianRBF,\n",
    "    fit_kernel_params\n",
    ")\n",
    "from EquationModel import CholInducedRKHS, CholOperatorModel, OperatorPDEModel\n",
    "from functools import partial\n",
    "\n",
    "import Optimizers\n",
    "import importlib\n",
    "importlib.reload(Optimizers)\n",
    "from Optimizers import CholeskyLM,SVD_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import cm\n",
    "import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# from pyDOE import lhs\n",
    "# #    import sobol_seq\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_rand_coll(n_coll, n_obs,seed, data_for_pinn = False): \n",
    "    '''\n",
    "    n_coll (int) : Integer less than 101 x 256.\n",
    "    n_obs (int)    : Integet less than n_coll.\n",
    "    seed (int)     : Seed to choose data point set.\n",
    "    '''     \n",
    "    # Generate data\n",
    "    data = scipy.io.loadmat('/home/juanfelipe/Desktop/research/keql/examples/burgers/data/burgers.mat')\n",
    "    # t\n",
    "    t = jnp.real(data['t'].flatten()[:,None])\n",
    "    # # Scale t\n",
    "    # scaler_t = MinMaxScaler()\n",
    "    # t = scaler_t.fit_transform(t)\n",
    "    # x\n",
    "    x = np.real(data['x'].flatten()[:,None])\n",
    "    # # Scale x\n",
    "    # scaler_x = MinMaxScaler()\n",
    "    # x = scaler_x.fit_transform(x)\n",
    "    # u true values\n",
    "    Exact = np.real(data['usol'])\n",
    "\n",
    "    # Fine meshgrid\n",
    "    T, X = np.meshgrid(t,x)\n",
    "\n",
    "    # Fine pairs (t,x)\n",
    "    X_star = np.hstack((T.flatten()[:,None], X.flatten()[:,None]))\n",
    "    # Fine u values\n",
    "    u_star = Exact.flatten()[:,None]\n",
    "    \n",
    "    # Triples at collocation point set\n",
    "    N_all = n_coll\n",
    "    triplets_fine = np.hstack([X_star,u_star])\n",
    "    triplets_all = jax.random.choice(key = jax.random.PRNGKey(0), a = triplets_fine, shape = (N_all,), replace=False)\n",
    "    \n",
    "    # Collocation point set\n",
    "    tx_all = triplets_all[:,:2]\n",
    "\n",
    "\n",
    "    N_obs = n_obs\n",
    "    triplets_obs = jax.random.choice(key = jax.random.PRNGKey(seed), a = triplets_fine, shape = (N_obs,), replace=False)\n",
    "    # triplets_obs = triplets_all[idx_obs,:] # Choose data point set from collocation point set\n",
    "    # Data point set\n",
    "    tx_obs = triplets_obs[:,:2]\n",
    "    u_obs = triplets_obs[:,-1]\n",
    "\n",
    "    u_star = triplets_fine[:,-1]\n",
    "\n",
    "    # Invert them to be ready for PINNSR\n",
    "    if data_for_pinn:\n",
    "        tx_train = tx_train.at[:,[1,0]].set(tx_train[:,[0,1]])\n",
    "\n",
    "        tx_val = tx_val.at[:,[1,0]].set(tx_val[:,[0,1]])\n",
    "\n",
    "        tx_all = tx_all.at[:,[1,0]].set(tx_all[:,[0,1]])\n",
    "\n",
    "        X_star = X_star.at[:,[1,0]].set(X_star[:,[0,1]])\n",
    "\n",
    "        triplets_fine = triplets_fine.at[:,[1,0]].set(triplets_fine[:,[0,1]])\n",
    "    \n",
    "    return tx_obs, u_obs, tx_all, u_star, X_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.03724345 2.01946685]\n"
     ]
    }
   ],
   "source": [
    "# n_coll_t = 30\n",
    "# n_coll_x=30\n",
    "n_obs = 50\n",
    "run = 100\n",
    "\n",
    "n_coll = 2500\n",
    "\n",
    "tx_obs, u_obs, tx_all, u_star, X_star = (\n",
    "    get_data_rand_coll(n_coll = n_coll,n_obs = n_obs,seed=run)\n",
    ")\n",
    "tx_all = jnp.vstack([tx_all,jnp.vstack([jnp.zeros(30),jnp.linspace(-8,8,30)]).T])\n",
    "\n",
    "# Run 1_5 step method\n",
    "\n",
    "u_operators = (eval_k,)\n",
    "feature_operators = (eval_k,dx_k,dxx_k)\n",
    "\n",
    "# Choose u kernel\n",
    "def param_ani_gaussian_RBF(x,y,params):\n",
    "    lengthscales = log1pexp(params)\n",
    "    return get_anisotropic_gaussianRBF(1.,jnp.diag(lengthscales))(x,y)\n",
    "\n",
    "fitted_params,ml_value = fit_kernel_params(param_ani_gaussian_RBF,tx_obs,u_obs,jnp.zeros(2))\n",
    "ML_lengthscales = log1pexp(fitted_params)\n",
    "print(1/(jnp.sqrt(ML_lengthscales)))\n",
    "k_u = get_anisotropic_gaussianRBF(1.,jnp.diag(jnp.array([1.,1.])))\n",
    "\n",
    "# RKHS class for u\n",
    "u_model = CholInducedRKHS(\n",
    "    tx_all,\n",
    "    u_operators,\n",
    "    k_u,\n",
    "    nugget_size = 1e-8\n",
    "    )\n",
    "u_params_init = u_model.get_fitted_params(tx_obs,u_obs)\n",
    "\n",
    "grid_features_init = (\n",
    "    (u_model.evaluate_operators(feature_operators,tx_all,u_params_init))\n",
    "    .reshape(\n",
    "            len(tx_all),\n",
    "            len(feature_operators),\n",
    "            order = 'F'\n",
    "        )\n",
    ")\n",
    "grid_features_init = jnp.hstack([tx_all,grid_features_init])\n",
    "num_P_inducing = 500\n",
    "P_inducing_points = jax.random.choice(jax.random.PRNGKey(13),grid_features_init,(num_P_inducing,))\n",
    "\n",
    "\n",
    "# Choose kernel for P\n",
    "k_P_u_part = get_centered_scaled_poly_kernel(2,grid_features_init[:,2:],c=1.,scaling = 'diagonal')\n",
    "\n",
    "def k_P(x,y):\n",
    "    return k_P_u_part(x[2:],y[2:])\n",
    "P_model = InducedOperatorModel(P_inducing_points,k_P)\n",
    "\n",
    "# Equation model that has u and P object\n",
    "EqnModel = SplitOperatorPDEModel(\n",
    "    P_model,\n",
    "    (u_model,),\n",
    "    (tx_obs,),\n",
    "    (u_obs,),\n",
    "    (tx_all,),\n",
    "    feature_operators,\n",
    "    rhs_operator=dt_k,\n",
    "    datafit_weight = 100,\n",
    "    num_P_operator_params=num_P_inducing\n",
    ")\n",
    "ut_init = EqnModel.apply_rhs_op_single(u_model,u_params_init,EqnModel.collocation_points[0])\n",
    "P_params_init = P_model.get_fitted_params(grid_features_init,ut_init,lam = 1e-3)\n",
    "params_init = jnp.hstack([u_params_init,P_params_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = jax.random.normal(jax.random.PRNGKey(304),shape = (300,EqnModel.residual_dimension))/jnp.sqrt(300)\n",
    "\n",
    "#@partial(jax.jit,static_argnames = 'size')\n",
    "\n",
    "@jax.jit\n",
    "def sketch_jac(params):\n",
    "    primals,F_vjp = jax.vjp(EqnModel.F,params)\n",
    "    SJ = jax.vmap(F_vjp)(sketch)[0]\n",
    "    return SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d729b0f4284029b2293c87e858a7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:  0.0015574354215858828\n",
      "Iteration 100:  6.826753958606303e-05\n",
      "Iteration 200:  3.986134243932362e-05\n",
      "Iteration 300:  2.784689354185507e-05\n",
      "Iteration 400:  2.1993528982141498e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5753626fe7740eea41cedc220ad928c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:  1.8600368297105102e-05\n",
      "Iteration 100:  9.388248166332159e-06\n",
      "Iteration 200:  6.833101337822985e-06\n",
      "Iteration 300:  5.3798324176885835e-06\n",
      "Iteration 400:  4.429673614901269e-06\n"
     ]
    }
   ],
   "source": [
    "from jax.scipy.linalg import solve\n",
    "jit_valgrad = jax.jit(jax.value_and_grad(EqnModel.loss))\n",
    "\n",
    "params = params_init\n",
    "num_steps = 500\n",
    "fvals_SLM = []\n",
    "for i in tqdm(range(num_steps)):\n",
    "    val,g = jit_valgrad(params)\n",
    "    SJ = sketch_jac(params)\n",
    "    params = params - 0.2 * solve(SJ.T@SJ + 1e-2 * jnp.identity(len(params_init)),g,assume_a = 'pos')\n",
    "    if i%100==0:\n",
    "        print(f\"Iteration {i}: \",val)\n",
    "    fvals_SLM.append(val)\n",
    "for i in tqdm(range(num_steps)):\n",
    "    val,g = jit_valgrad(params)\n",
    "    SJ = sketch_jac(params)\n",
    "    params = params - 0.2 * solve(SJ.T@SJ + 1e-3 * jnp.identity(len(params_init)),g,assume_a = 'pos')\n",
    "    if i%100==0:\n",
    "        print(f\"Iteration {i}: \",val)\n",
    "    fvals_SLM.append(val)\n",
    "\n",
    "fvals_SLM = jnp.array(fvals_SLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([-2.24255836e-10,  1.13307128e-07,  3.94358958e-08, ...,\n",
       "        -2.77598301e-06, -2.59843180e-06, -2.43500809e-06], dtype=float64),\n",
       " Array([-1.46655320e-04, -1.24436270e-01, -1.18475954e-01, ...,\n",
       "        -2.66793995e-06, -2.43691044e-06, -2.35040780e-06], dtype=float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.jvp(EqnModel.F,(params_init,),(params_init,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.jacfwd(EqnModel.F)(params_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fval,Jfunc = jax.linearize(EqnModel.F,params_init)\n",
    "J = jax.lax.map(Jfunc,jnp.identity(len(params_init)), batch_size=1000).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.vmap(Jfunc)(jnp.identity(len(params_init))[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fval,Jfunc = jax.linearize(EqnModel.F,params_init)\n",
    "# J = jax.vmap(Jfunc)(jnp.identity(len(params_init)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import lineax as lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.linalg import solve\n",
    "jit_valgrad = jax.jit(jax.value_and_grad(EqnModel.loss))\n",
    "\n",
    "params = params_init\n",
    "val,g = jit_valgrad(params)\n",
    "SJ = sketch_jac(params)\n",
    "# step = \n",
    "    # params = params - solve(SJ.T@SJ + 1e-2 * jnp.identity(len(params_init)),g,assume_a = 'pos')\n",
    "    # if i%100==0:\n",
    "    #     print(f\"Iteration {i}: \",val)\n",
    "    # fvals_SLM.append(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-2\n",
    "U,sigma,Vt = jnp.linalg.svd(SJ,full_matrices = False)\n",
    "D = sigma ** 2\n",
    "precon = lambda x:Vt.T@(D/(1+D/alpha))*(Vt@x)\n",
    "direct = jnp.linalg.inv(SJ.T@SJ + jnp.identity(len(params))*alpha)\n",
    "\n",
    "beta = 1.\n",
    "sv_rescale = (beta * D/(beta+D)).reshape(-1,1)\n",
    "M = 1/beta * jnp.identity(len(params)) - (1/(beta**2)) * Vt.T@(sv_rescale*Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3030, 2580)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4\n",
    "precon = lambda x:Vt.T@((sigma/(sigma**2+alpha))*(Vt@x))\n",
    "direct = jnp.linalg.inv(J.T@J + jnp.identity(len(params))*alpha)\n",
    "\n",
    "#precon_op = lx.FunctionLinearOperator(precon,params_init,tags = lx.positive_semidefinite_tag)\n",
    "precon_op = lx.MatrixLinearOperator(direct,tags = lx.positive_semidefinite_tag)\n",
    "\n",
    "J_op = lx.JacobianLinearOperator(lambda x,args:EqnModel.F(x),params)\n",
    "LM_hess = lx.TaggedLinearOperator(J_op.T@J_op  + alpha * lx.IdentityLinearOperator(params),lx.positive_semidefinite_tag)\n",
    "solver = lx.CG(rtol=1e-10, atol=1e-11,stabilise_every = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1022 15:32:54.854709 1968624 pjrt_stream_executor_client.cc:3084] Execution of replica 0 failed: INTERNAL: CustomCall failed: CpuCallback error: Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "  File \"/tmp/ipykernel_1968624/3302183111.py\", line 1, in <module>\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/equinox/_jit.py\", line 239, in __call__\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/equinox/_module.py\", line 1093, in __call__\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/equinox/_jit.py\", line 212, in _call\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/traceback_util.py\", line 180, in reraise_with_filtered_traceback\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/pjit.py\", line 338, in cache_miss\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/pjit.py\", line 188, in _python_pjit_helper\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/core.py\", line 2803, in bind\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/core.py\", line 442, in bind_with_trace\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/core.py\", line 955, in process_primitive\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/pjit.py\", line 1738, in _pjit_call_impl\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/pjit.py\", line 1714, in call_impl_cache_miss\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/pjit.py\", line 1668, in _pjit_call_impl_python\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/profiler.py\", line 333, in wrapper\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py\", line 1278, in __call__\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/interpreters/mlir.py\", line 2768, in _wrapped_callback\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/callback.py\", line 269, in _callback\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/callback.py\", line 97, in pure_callback_impl\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/jax/_src/callback.py\", line 71, in __call__\n",
      "  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/equinox/_errors.py\", line 89, in raises\n",
      "_EquinoxRuntimeError: The linear solver returned non-finite (NaN or inf) output. This usually means that the\n",
      "operator was not well-posed, and that the solver does not support this.\n",
      "\n",
      "If you are trying solve a linear least-squares problem then you should pass\n",
      "`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\n",
      "assumes that the operator is square and nonsingular.\n",
      "\n",
      "If you *were* expecting this solver to work with this operator, then it may be because:\n",
      "\n",
      "(a) the operator is singular, and your code has a bug; or\n",
      "\n",
      "(b) the operator was nearly singular (i.e. it had a high condition number:\n",
      "    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n",
      "    numerical instability issues; or\n",
      "\n",
      "(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n",
      "    that is does not actually satisfy.\n",
      "\n",
      "\n",
      "--------------------\n",
      "An error occurred during the runtime of your JAX program! Unfortunately you do not appear to be using `equinox.filter_jit` (perhaps you are using `jax.jit` instead?) and so further information about the error cannot be displayed. (Probably you are seeing a very large but uninformative error message right now.) Please wrap your program with `equinox.filter_jit`.\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "ename": "EquinoxRuntimeError",
     "evalue": "Above is the stack outside of JIT. Below is the stack inside of JIT:\n  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/equinox/internal/_primitive.py\", line 148, in _wrapper\n    out = rule(*args)\n          ^^^^^^^^^^^\n  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/lineax/_solve.py\", line 103, in _linear_solve_impl\n    solution, result, stats = result.error_if(\n                              ^^^^^^^^^^^^^^^^\nequinox.EquinoxRuntimeError: The linear solver returned non-finite (NaN or inf) output. This usually means that the\noperator was not well-posed, and that the solver does not support this.\n\nIf you are trying solve a linear least-squares problem then you should pass\n`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\nassumes that the operator is square and nonsingular.\n\nIf you *were* expecting this solver to work with this operator, then it may be because:\n\n(a) the operator is singular, and your code has a bug; or\n\n(b) the operator was nearly singular (i.e. it had a high condition number:\n    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n    numerical instability issues; or\n\n(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n    that is does not actually satisfy.\n\n-------------------\n\nAn error occurred during the runtime of your JAX program.\n\n1) Setting the environment variable `EQX_ON_ERROR=breakpoint` is usually the most useful\nway to debug such errors. This can be interacted with using most of the usual commands\nfor the Python debugger: `u` and `d` to move up and down frames, the name of a variable\nto print its value, etc.\n\n2) You may also like to try setting `JAX_DISABLE_JIT=1`. This will mean that you can\n(mostly) inspect the state of your program as if it was normal Python.\n\n3) See `https://docs.kidger.site/equinox/api/debug/` for more suggestions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEquinoxRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLM_hess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreconditioner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprecon_op\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;129;43m@g\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mEquinoxRuntimeError\u001b[0m: Above is the stack outside of JIT. Below is the stack inside of JIT:\n  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/equinox/internal/_primitive.py\", line 148, in _wrapper\n    out = rule(*args)\n          ^^^^^^^^^^^\n  File \"/home/alexh/miniconda3/envs/keql/lib/python3.12/site-packages/lineax/_solve.py\", line 103, in _linear_solve_impl\n    solution, result, stats = result.error_if(\n                              ^^^^^^^^^^^^^^^^\nequinox.EquinoxRuntimeError: The linear solver returned non-finite (NaN or inf) output. This usually means that the\noperator was not well-posed, and that the solver does not support this.\n\nIf you are trying solve a linear least-squares problem then you should pass\n`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\nassumes that the operator is square and nonsingular.\n\nIf you *were* expecting this solver to work with this operator, then it may be because:\n\n(a) the operator is singular, and your code has a bug; or\n\n(b) the operator was nearly singular (i.e. it had a high condition number:\n    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n    numerical instability issues; or\n\n(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n    that is does not actually satisfy.\n\n-------------------\n\nAn error occurred during the runtime of your JAX program.\n\n1) Setting the environment variable `EQX_ON_ERROR=breakpoint` is usually the most useful\nway to debug such errors. This can be interacted with using most of the usual commands\nfor the Python debugger: `u` and `d` to move up and down frames, the name of a variable\nto print its value, etc.\n\n2) You may also like to try setting `JAX_DISABLE_JIT=1`. This will mean that you can\n(mostly) inspect the state of your program as if it was normal Python.\n\n3) See `https://docs.kidger.site/equinox/api/debug/` for more suggestions.\n"
     ]
    }
   ],
   "source": [
    "out = lx.linear_solve(LM_hess, g, solver,options = {'preconditioner':precon_op,'y0':direct@g})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_steps': None, 'num_steps': Array(2, dtype=int64)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.00032402, dtype=float64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_valgrad(params - out.value)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.00155744, dtype=float64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_valgrad(params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.0015487, dtype=float64),\n",
       " Array([ 1.71995741e-04,  9.62767443e-04,  2.40964628e-05, ...,\n",
       "         1.22681015e-09, -8.04242069e-10,  7.89538012e-10], dtype=float64))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_valgrad(params - precon_op.mv(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.0015487, dtype=float64),\n",
       " Array([ 1.71995741e-04,  9.62767443e-04,  2.40964628e-05, ...,\n",
       "         1.22681015e-09, -8.04242069e-10,  7.89538012e-10], dtype=float64))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_valgrad(params - precon_op.mv(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.00152983, dtype=float64),\n",
       " Array([ 3.43140916e-04, -3.55518935e-03, -1.83517427e-05, ...,\n",
       "         4.40956583e-09, -3.01421386e-09,  1.88361300e-09], dtype=float64))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_valgrad(params - g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import lineax as lx\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "y = jax.random.normal(key, (10,))\n",
    "D = jnp.linspace(1,10000,10)\n",
    "def quadratic_fn(y, args):\n",
    "  return jax.numpy.sum(D*(y - 1)**2)\n",
    "\n",
    "gradient_fn = jax.grad(quadratic_fn)\n",
    "hessian = lx.JacobianLinearOperator(gradient_fn, y, tags=lx.positive_semidefinite_tag)\n",
    "solver = lx.CG(rtol=1e-6, atol=1e-6)\n",
    "out = lx.linear_solve(hessian, gradient_fn(y, args=None), solver)\n",
    "minimum = y - out.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
