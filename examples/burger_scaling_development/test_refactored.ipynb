{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_default_device\", jax.devices()[1])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "from tqdm.auto import tqdm\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from importlib import reload\n",
    "import KernelTools\n",
    "reload(KernelTools)\n",
    "from KernelTools import *\n",
    "from EquationModel import OperatorModel,SplitOperatorPDEModel,OperatorPDEModel,build_batched_jac_func,InducedOperatorModel\n",
    "from evaluation_metrics import compute_results    \n",
    "from data_utils import MinMaxScaler\n",
    "from evaluation_metrics import get_nrmse\n",
    "\n",
    "from Kernels import log1pexp,inv_log1pexp\n",
    "from Kernels import (\n",
    "    get_centered_scaled_poly_kernel,\n",
    "    get_anisotropic_gaussianRBF,\n",
    "    fit_kernel_params\n",
    ")\n",
    "from EquationModel import CholInducedRKHS, CholOperatorModel, OperatorPDEModel\n",
    "from functools import partial\n",
    "\n",
    "import Optimizers\n",
    "import importlib\n",
    "importlib.reload(Optimizers)\n",
    "from Optimizers import CholeskyLM,SVD_LM,SketchedLM\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_rand_coll(n_coll, n_obs,seed, data_for_pinn = False): \n",
    "    '''\n",
    "    n_coll (int) : Integer less than 101 x 256.\n",
    "    n_obs (int)    : Integet less than n_coll.\n",
    "    seed (int)     : Seed to choose data point set.\n",
    "    '''     \n",
    "    # Generate data\n",
    "    data = scipy.io.loadmat('/home/juanfelipe/Desktop/research/keql/examples/burgers/data/burgers.mat')\n",
    "    # t\n",
    "    t = jnp.real(data['t'].flatten()[:,None])\n",
    "    # # Scale t\n",
    "    # scaler_t = MinMaxScaler()\n",
    "    # t = scaler_t.fit_transform(t)\n",
    "    # x\n",
    "    x = np.real(data['x'].flatten()[:,None])\n",
    "    # # Scale x\n",
    "    # scaler_x = MinMaxScaler()\n",
    "    # x = scaler_x.fit_transform(x)\n",
    "    # u true values\n",
    "    Exact = np.real(data['usol'])\n",
    "\n",
    "    # Fine meshgrid\n",
    "    T, X = np.meshgrid(t,x)\n",
    "\n",
    "    # Fine pairs (t,x)\n",
    "    X_star = np.hstack((T.flatten()[:,None], X.flatten()[:,None]))\n",
    "    # Fine u values\n",
    "    u_star = Exact.flatten()[:,None]\n",
    "    \n",
    "    # Triples at collocation point set\n",
    "    N_all = n_coll\n",
    "    triplets_fine = np.hstack([X_star,u_star])\n",
    "    triplets_all = jax.random.choice(key = jax.random.PRNGKey(0), a = triplets_fine, shape = (N_all,), replace=False)\n",
    "    \n",
    "    # Collocation point set\n",
    "    tx_all = triplets_all[:,:2]\n",
    "\n",
    "\n",
    "    N_obs = n_obs\n",
    "    triplets_obs = jax.random.choice(key = jax.random.PRNGKey(seed), a = triplets_fine, shape = (N_obs,), replace=False)\n",
    "    # triplets_obs = triplets_all[idx_obs,:] # Choose data point set from collocation point set\n",
    "    # Data point set\n",
    "    tx_obs = triplets_obs[:,:2]\n",
    "    u_obs = triplets_obs[:,-1]\n",
    "\n",
    "    u_star = triplets_fine[:,-1]\n",
    "\n",
    "    # Invert them to be ready for PINNSR\n",
    "    if data_for_pinn:\n",
    "        tx_train = tx_train.at[:,[1,0]].set(tx_train[:,[0,1]])\n",
    "\n",
    "        tx_val = tx_val.at[:,[1,0]].set(tx_val[:,[0,1]])\n",
    "\n",
    "        tx_all = tx_all.at[:,[1,0]].set(tx_all[:,[0,1]])\n",
    "\n",
    "        X_star = X_star.at[:,[1,0]].set(X_star[:,[0,1]])\n",
    "\n",
    "        triplets_fine = triplets_fine.at[:,[1,0]].set(triplets_fine[:,[0,1]])\n",
    "    \n",
    "    return tx_obs, u_obs, tx_all, u_star, X_star\n",
    "\n",
    "import time\n",
    "from jax.scipy.linalg import solve\n",
    "\n",
    "import time\n",
    "from jax.scipy.linalg import solve\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class LMParams:\n",
    "    \"\"\"\n",
    "    max_iter : int, optional\n",
    "        by default 201\n",
    "    tol : float, optional\n",
    "        Gradient norm stopping tolerance\n",
    "    cmin : float, optional\n",
    "        Minimum armijo ratio to accept step, by default 0.1\n",
    "    line_search_increase_ratio : float, optional\n",
    "        constant to increase reg strength by in backtracking line search, by default 1.5\n",
    "    max_line_search_iterations : int, optional\n",
    "        by default 20\n",
    "    min_alpha : float, optional\n",
    "        min damping strength, by default 1e-6\n",
    "    max_alpha : float, optional\n",
    "        max damping strength, by default 50.\n",
    "    init_alpha : float, optional\n",
    "        initial damping strength, by default 3.\n",
    "    step_adapt_multipler : float, optional\n",
    "        value to use for adapting alpha, by default 1.2\n",
    "    callback : callable, optional\n",
    "        function called to print another loss each iteration, by default None\n",
    "    print_every : int, optional\n",
    "        How often to print convergence data, by default 50\n",
    "    \"\"\"\n",
    "    max_iter: int = 201\n",
    "    tol: float = 1e-8\n",
    "    cmin: float = 0.05\n",
    "    line_search_increase_ratio: float = 1.5\n",
    "    max_line_search_iterations: int = 20\n",
    "    min_alpha: float = 1e-6\n",
    "    max_alpha: float = 50.0\n",
    "    init_alpha: float = 3.0\n",
    "    step_adapt_multiplier: float = 1.2\n",
    "    callback: callable = None\n",
    "    print_every: int = 50\n",
    "    track_iterates: bool = False\n",
    "\n",
    "@dataclass\n",
    "class ConvergenceHistory:\n",
    "    track_iterates: bool = False\n",
    "    loss_vals: list = field(default_factory=list)\n",
    "    JtRes: list = field(default_factory=list)\n",
    "    iterate_history: list = field(default_factory=list)\n",
    "    improvement_ratios: list = field(default_factory=list)\n",
    "    alpha_vals: list = field(default_factory=list)\n",
    "    cumulative_time: list = field(default_factory=list)\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        loss,\n",
    "        JtRes,\n",
    "        iterate,\n",
    "        armijo_ratio,\n",
    "        alpha,\n",
    "        cumulative_time\n",
    "        ):\n",
    "        # Append the new values to the corresponding lists\n",
    "        self.loss_vals.append(loss)\n",
    "        self.JtRes.append(JtRes)\n",
    "        self.improvement_ratios.append(armijo_ratio)\n",
    "        self.alpha_vals.append(alpha)\n",
    "        self.cumulative_time.append(cumulative_time)\n",
    "        \n",
    "        # Conditionally track iterates if enabled\n",
    "        if self.track_iterates:\n",
    "            self.iterate_history.append(iterate)\n",
    "\n",
    "    def finish(self):\n",
    "        # Convert lists to JAX arrays\n",
    "        self.loss_vals = jnp.array(self.loss_vals)\n",
    "        self.JtRes = jnp.array(self.JtRes)\n",
    "        self.improvement_ratios = jnp.array(self.improvement_ratios)\n",
    "        self.alpha_vals = jnp.array(self.alpha_vals)\n",
    "        self.cumulative_time = jnp.array(self.cumulative_time)\n",
    "        if self.track_iterates:\n",
    "            self.iterate_history = jnp.array(self.iterate_history)\n",
    "\n",
    "def RefactoredCholeskyLM(\n",
    "        init_params,\n",
    "        model,\n",
    "        beta,\n",
    "        optParams: LMParams = LMParams()\n",
    "        ):\n",
    "    \"\"\"Adaptively regularized Levenberg Marquardt optimizer\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_params : jax array\n",
    "        initial guess\n",
    "    model :\n",
    "        Object that contains model.F, and model.jac, and model.damping_matrix\n",
    "    beta : float\n",
    "        (global) regularization strength\n",
    "    optParams: LMParams\n",
    "        optimizer hyperparameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    solution\n",
    "        approximate minimizer\n",
    "    convergence_dict\n",
    "        dictionary of data tracking convergence\n",
    "    \"\"\"\n",
    "    conv_history = ConvergenceHistory(optParams.track_iterates)\n",
    "    start_time = time.time()\n",
    "    params = init_params.copy()\n",
    "    J = model.jac(params)\n",
    "    residuals = model.F(params)\n",
    "    damping_matrix = model.damping_matrix(params)\n",
    "    alpha = optParams.init_alpha\n",
    "\n",
    "    conv_history.update(\n",
    "        loss = (1/2)*jnp.sum(residuals**2) + (1/2)*beta * params.T@damping_matrix@params,\n",
    "        JtRes = jnp.linalg.norm(J.T@residuals + beta * damping_matrix@params),\n",
    "        iterate = params,\n",
    "        armijo_ratio = 1.,\n",
    "        alpha = alpha,\n",
    "        cumulative_time = time.time() - start_time\n",
    "    )\n",
    "\n",
    "    # TODO: This pair of functions can be handled more elegantly\n",
    "    # Make something like an objective_data object\n",
    "    @jax.jit\n",
    "    def evaluate_objective(params):\n",
    "        J = model.jac(params)\n",
    "        residuals = model.F(params)\n",
    "        damping_matrix = model.damping_matrix(params)\n",
    "        loss = (1/2)*jnp.sum(residuals**2) + (1/2)*beta * params.T@damping_matrix@params\n",
    "        JtJ = J.T@J\n",
    "        rhs = J.T@residuals + beta * damping_matrix@params\n",
    "        return J,residuals,damping_matrix,loss,JtJ,rhs\n",
    "    \n",
    "    @jax.jit\n",
    "    def compute_step(params,alpha,J,JtJ,residuals,rhs,previous_loss,damping_matrix):\n",
    "        M = JtJ + (alpha + beta) * damping_matrix\n",
    "        step = solve(M,rhs,assume_a = 'pos')\n",
    "        new_params = params - step\n",
    "        new_reg_norm = beta * new_params.T@damping_matrix@new_params\n",
    "        new_loss = (1/2)*(jnp.sum(model.F(new_params)**2) + new_reg_norm)\n",
    "        predicted_loss = (1/2)*(jnp.sum((J@step-residuals)**2) + new_reg_norm)\n",
    "        improvement_ratio = (previous_loss - new_loss)/(previous_loss - predicted_loss)\n",
    "        return step,new_params,new_loss,improvement_ratio\n",
    "\n",
    "    def LevenbergMarquadtUpdate(params,alpha):\n",
    "        J,residuals,damping_matrix,loss,JtJ,rhs = evaluate_objective(params)\n",
    "        alpha =jnp.clip(alpha,optParams.min_alpha,optParams.max_alpha)\n",
    "        for i in range(optParams.max_line_search_iterations):\n",
    "\n",
    "            step,new_params,new_loss,improvement_ratio = (\n",
    "                compute_step(params,alpha,J,JtJ,residuals,rhs,loss,damping_matrix)\n",
    "            )\n",
    "            if improvement_ratio >= optParams.cmin:\n",
    "                #Check if we get at least some proportion of predicted improvement from local model\n",
    "                succeeded = True\n",
    "                return new_params, new_loss, rhs, improvement_ratio,alpha,succeeded\n",
    "            else:\n",
    "                alpha = optParams.line_search_increase_ratio * alpha\n",
    "            succeeded = False\n",
    "        return new_params, new_loss, rhs, improvement_ratio,alpha,succeeded\n",
    "\n",
    "    for i in tqdm(range(optParams.max_iter)):\n",
    "        params,loss,rhs,improvement_ratio,alpha,succeeded = LevenbergMarquadtUpdate(params,alpha)\n",
    "        # Get new value for alpha\n",
    "        multiplier = optParams.step_adapt_multiplier\n",
    "        if improvement_ratio <= 0.2:\n",
    "            alpha = multiplier * alpha\n",
    "        if improvement_ratio >= 0.8:\n",
    "            alpha = alpha/multiplier\n",
    "\n",
    "        if succeeded==False:\n",
    "            print(\"Line Search Failed!\")\n",
    "            print(\"Final Iteration Results\")\n",
    "            print(\n",
    "                f\"Iteration {i}, loss = {loss:.4},\"\n",
    "                f\" Jres = {conv_history.JtRes[-1]:.4}, alpha = {alpha:.4},\"\n",
    "                f\" improvement_ratio = {improvement_ratio:.4}\"\n",
    "                )\n",
    "            conv_history.finish()\n",
    "            return params,conv_history\n",
    "\n",
    "        conv_history.update(\n",
    "            loss = loss,\n",
    "            JtRes = jnp.linalg.norm(rhs),\n",
    "            iterate = params,\n",
    "            armijo_ratio = improvement_ratio,\n",
    "            alpha = alpha,\n",
    "            cumulative_time = time.time() - start_time\n",
    "        )\n",
    "\n",
    "        if conv_history.JtRes[-1]<=optParams.tol:\n",
    "            break\n",
    "        if i%optParams.print_every ==0 or i<=5 or i == optParams.max_iter:\n",
    "            print(\n",
    "                f\"Iteration {i}, loss = {loss:.4},\"\n",
    "                f\" Jres = {conv_history.JtRes[-1]:.4}, alpha = {alpha:.4},\"\n",
    "                f\" improvement_ratio = {improvement_ratio:.4}\"\n",
    "                )\n",
    "            if optParams.callback:\n",
    "                optParams.callback(params)\n",
    "    conv_history.finish()\n",
    "    return params,conv_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RefactoredCholeskyLM(\n",
    "        init_params,\n",
    "        model,\n",
    "        beta,\n",
    "        optParams: LMParams = LMParams()\n",
    "        ):\n",
    "    \"\"\"Adaptively regularized Levenberg Marquardt optimizer\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_params : jax array\n",
    "        initial guess\n",
    "    model :\n",
    "        Object that contains model.F, and model.jac, and model.damping_matrix\n",
    "    beta : float\n",
    "        (global) regularization strength\n",
    "    optParams: LMParams\n",
    "        optimizer hyperparameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    solution\n",
    "        approximate minimizer\n",
    "    convergence_dict\n",
    "        dictionary of data tracking convergence\n",
    "    \"\"\"\n",
    "    conv_history = ConvergenceHistory(optParams.track_iterates)\n",
    "    start_time = time.time()\n",
    "    params = init_params.copy()\n",
    "    J = model.jac(params)\n",
    "    residuals = model.F(params)\n",
    "    damping_matrix = model.damping_matrix(params)\n",
    "    alpha = optParams.init_alpha\n",
    "\n",
    "    conv_history.update(\n",
    "        loss = (1/2)*jnp.sum(residuals**2) + (1/2)*beta * params.T@damping_matrix@params,\n",
    "        JtRes = jnp.linalg.norm(J.T@residuals + beta * damping_matrix@params),\n",
    "        iterate = params,\n",
    "        armijo_ratio = 1.,\n",
    "        alpha = alpha,\n",
    "        cumulative_time = time.time() - start_time\n",
    "    )\n",
    "\n",
    "    @jax.jit\n",
    "    def evaluate_objective(params):\n",
    "        J = model.jac(params)\n",
    "        residuals = model.F(params)\n",
    "        damping_matrix = model.damping_matrix(params)\n",
    "        loss = (1/2)*jnp.sum(residuals**2) + (1/2)*beta * params.T@damping_matrix@params\n",
    "        JtJ = J.T@J\n",
    "        rhs = J.T@residuals + beta * damping_matrix@params\n",
    "        return J,residuals,damping_matrix,loss,JtJ,rhs\n",
    "    \n",
    "    @jax.jit\n",
    "    def compute_step(alpha,JtJ,rhs,previous_loss):\n",
    "        M = JtJ + (alpha + beta) * damping_matrix\n",
    "        step = solve(M,rhs,assume_a = 'pos')\n",
    "        new_params = params - step\n",
    "        new_reg_norm = beta * new_params.T@damping_matrix@new_params\n",
    "        new_loss = (1/2)*(jnp.sum(model.F(new_params)**2) + new_reg_norm)\n",
    "        predicted_loss = (1/2)*(jnp.sum((J@step-residuals)**2) + new_reg_norm)\n",
    "        improvement_ratio = (previous_loss - new_loss)/(previous_loss - predicted_loss)\n",
    "        return new_params,new_loss,improvement_ratio\n",
    "\n",
    "    def LevenbergMarquadtUpdate(params,alpha):\n",
    "        \"\"\"TODO: Wrap up this into something a little more modular\"\"\"\n",
    "\n",
    "        J,residuals,damping_matrix,loss,JtJ,rhs = evaluate_objective(params)\n",
    "        alpha =jnp.clip(alpha,optParams.min_alpha,optParams.max_alpha)\n",
    "        for i in range(optParams.max_line_search_iterations):\n",
    "            new_params,new_loss,improvement_ratio = compute_step(alpha,JtJ,rhs,previous_loss = loss)\n",
    "\n",
    "            if improvement_ratio >= optParams.cmin:\n",
    "                #Check if we get at least some proportion of predicted improvement from local model\n",
    "                succeeded = True\n",
    "                return new_params, new_loss, rhs, improvement_ratio,alpha,succeeded\n",
    "            else:\n",
    "                alpha = optParams.line_search_increase_ratio * alpha\n",
    "            succeeded = False\n",
    "        return new_params, new_loss, rhs, improvement_ratio,alpha,succeeded\n",
    "\n",
    "    for i in tqdm(range(optParams.max_iter)):\n",
    "        params,loss,rhs,improvement_ratio,alpha,succeeded = LevenbergMarquadtUpdate(params,alpha)\n",
    "        # Get new value for alpha\n",
    "        multiplier = optParams.step_adapt_multiplier\n",
    "        if improvement_ratio <= 0.2:\n",
    "            alpha = multiplier * alpha\n",
    "        if improvement_ratio >= 0.8:\n",
    "            alpha = alpha/multiplier\n",
    "\n",
    "        if succeeded==False:\n",
    "            print(\"Line Search Failed!\")\n",
    "            print(\"Final Iteration Results\")\n",
    "            print(\n",
    "                f\"Iteration {i}, loss = {loss:.4},\"\n",
    "                f\" Jres = {conv_history.JtRes[-1]:.4}, alpha = {alpha:.4},\"\n",
    "                f\" improvement_ratio = {improvement_ratio:.4}\"\n",
    "                )\n",
    "            conv_history.finish()\n",
    "            return params,conv_history\n",
    "\n",
    "        conv_history.update(\n",
    "            loss = loss,\n",
    "            JtRes = jnp.linalg.norm(rhs),\n",
    "            iterate = params,\n",
    "            armijo_ratio = improvement_ratio,\n",
    "            alpha = alpha,\n",
    "            cumulative_time = time.time() - start_time\n",
    "        )\n",
    "\n",
    "        if conv_history.JtRes[-1]<=optParams.tol:\n",
    "            break\n",
    "        if i%optParams.print_every ==0 or i<=5 or i == optParams.max_iter:\n",
    "            print(\n",
    "                f\"Iteration {i}, loss = {loss:.4},\"\n",
    "                f\" Jres = {conv_history.JtRes[-1]:.4}, alpha = {alpha:.4},\"\n",
    "                f\" improvement_ratio = {improvement_ratio:.4}\"\n",
    "                )\n",
    "            if optParams.callback:\n",
    "                optParams.callback(params)\n",
    "    conv_history.finish()\n",
    "    return params,conv_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.03724345 2.01946685]\n"
     ]
    }
   ],
   "source": [
    "# n_coll_t = 30\n",
    "# n_coll_x=30\n",
    "n_obs = 50\n",
    "run = 100\n",
    "\n",
    "n_coll = 200\n",
    "\n",
    "tx_obs, u_obs, tx_all, u_star, X_star = (\n",
    "    get_data_rand_coll(n_coll = n_coll,n_obs = n_obs,seed=run)\n",
    ")\n",
    "tx_all = jnp.vstack([tx_all,jnp.vstack([jnp.zeros(30),jnp.linspace(-8,8,30)]).T])\n",
    "\n",
    "# Run 1_5 step method\n",
    "\n",
    "u_operators = (eval_k,)\n",
    "feature_operators = (eval_k,dx_k,dxx_k)\n",
    "\n",
    "# Choose u kernel\n",
    "def param_ani_gaussian_RBF(x,y,params):\n",
    "    lengthscales = log1pexp(params)\n",
    "    return get_anisotropic_gaussianRBF(1.,jnp.diag(lengthscales))(x,y)\n",
    "\n",
    "fitted_params,ml_value = fit_kernel_params(param_ani_gaussian_RBF,tx_obs,u_obs,jnp.zeros(2))\n",
    "ML_lengthscales = log1pexp(fitted_params)\n",
    "print(1/(jnp.sqrt(ML_lengthscales)))\n",
    "k_u = get_anisotropic_gaussianRBF(1.,jnp.diag(jnp.array([1.,1.])))\n",
    "\n",
    "# RKHS class for u\n",
    "u_model = CholInducedRKHS(\n",
    "    tx_all,\n",
    "    u_operators,\n",
    "    k_u,\n",
    "    nugget_size = 1e-8\n",
    "    )\n",
    "u_params_init = u_model.get_fitted_params(tx_obs,u_obs)\n",
    "\n",
    "grid_features_init = (\n",
    "    (u_model.evaluate_operators(feature_operators,tx_all,u_params_init))\n",
    "    .reshape(\n",
    "            len(tx_all),\n",
    "            len(feature_operators),\n",
    "            order = 'F'\n",
    "        )\n",
    ")\n",
    "grid_features_init = jnp.hstack([tx_all,grid_features_init])\n",
    "num_P_inducing = 500\n",
    "P_inducing_points = jax.random.choice(jax.random.PRNGKey(13),grid_features_init,(num_P_inducing,))\n",
    "\n",
    "\n",
    "# Choose kernel for P\n",
    "k_P_u_part = get_centered_scaled_poly_kernel(2,grid_features_init[:,2:],c=1.,scaling = 'diagonal')\n",
    "\n",
    "def k_P(x,y):\n",
    "    return k_P_u_part(x[2:],y[2:])\n",
    "P_model = InducedOperatorModel(P_inducing_points,k_P)\n",
    "\n",
    "# Equation model that has u and P object\n",
    "EqnModel = SplitOperatorPDEModel(\n",
    "    P_model,\n",
    "    (u_model,),\n",
    "    (tx_obs,),\n",
    "    (u_obs,),\n",
    "    (tx_all,),\n",
    "    feature_operators,\n",
    "    rhs_operator=dt_k,\n",
    "    datafit_weight = 100,\n",
    "    num_P_operator_params=num_P_inducing\n",
    ")\n",
    "ut_init = EqnModel.apply_rhs_op_single(u_model,u_params_init,EqnModel.collocation_points[0])\n",
    "P_params_init = P_model.get_fitted_params(grid_features_init,ut_init,lam = 1e-3)\n",
    "params_init = jnp.hstack([u_params_init,P_params_init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1749b7cd22bb460fa4ca24d8ff32a5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.001958, Jres = 0.01021, alpha = 2.5, improvement_ratio = 1.0\n",
      "Iteration 1, loss = 0.00193, Jres = 0.008847, alpha = 2.083, improvement_ratio = 1.001\n",
      "Iteration 2, loss = 0.001899, Jres = 0.008293, alpha = 1.736, improvement_ratio = 1.001\n",
      "Iteration 3, loss = 0.001864, Jres = 0.008006, alpha = 1.447, improvement_ratio = 1.002\n",
      "Iteration 4, loss = 0.001824, Jres = 0.007814, alpha = 1.206, improvement_ratio = 1.003\n",
      "Iteration 5, loss = 0.001777, Jres = 0.007667, alpha = 1.005, improvement_ratio = 1.004\n",
      "Iteration 50, loss = 9.336e-06, Jres = 0.000408, alpha = 0.0002747, improvement_ratio = 1.027\n",
      "Iteration 100, loss = 1.552e-06, Jres = 8.74e-06, alpha = 8.333e-07, improvement_ratio = 0.9992\n",
      "Iteration 150, loss = 1.429e-06, Jres = 8.735e-07, alpha = 8.333e-07, improvement_ratio = 1.001\n",
      "Iteration 200, loss = 1.387e-06, Jres = 6.355e-07, alpha = 8.333e-07, improvement_ratio = 1.002\n"
     ]
    }
   ],
   "source": [
    "params,convergence_data = CholeskyLM(\n",
    "    params_init.copy(),\n",
    "    EqnModel,\n",
    "    beta = 0.,\n",
    "    max_iter = 201,\n",
    "    init_alpha=3.,\n",
    "    print_every = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10beb25622824fb085c7a1c31842e448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.001958, Jres = 0.01021, alpha = 2.5, improvement_ratio = 1.0\n",
      "Iteration 1, loss = 0.00193, Jres = 0.008847, alpha = 2.083, improvement_ratio = 1.001\n",
      "Iteration 2, loss = 0.001899, Jres = 0.008293, alpha = 1.736, improvement_ratio = 1.001\n",
      "Iteration 3, loss = 0.001864, Jres = 0.008006, alpha = 1.447, improvement_ratio = 1.002\n",
      "Iteration 4, loss = 0.001824, Jres = 0.007814, alpha = 1.206, improvement_ratio = 1.003\n",
      "Iteration 5, loss = 0.001777, Jres = 0.007667, alpha = 1.005, improvement_ratio = 1.004\n",
      "Iteration 50, loss = 9.336e-06, Jres = 0.000408, alpha = 0.0002747, improvement_ratio = 1.027\n",
      "Iteration 100, loss = 1.552e-06, Jres = 8.74e-06, alpha = 8.333e-07, improvement_ratio = 0.9992\n",
      "Iteration 150, loss = 1.429e-06, Jres = 8.735e-07, alpha = 8.333e-07, improvement_ratio = 1.001\n",
      "Iteration 200, loss = 1.387e-06, Jres = 6.355e-07, alpha = 8.333e-07, improvement_ratio = 1.002\n"
     ]
    }
   ],
   "source": [
    "optparams = LMParams(max_iter = 10)\n",
    "\n",
    "params,convergence = RefactoredCholeskyLM(params_init.copy(),EqnModel,beta = 0.)#,optParams = optparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(convergence.loss_vals)\n",
    "plt.yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
